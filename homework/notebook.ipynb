{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d340076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerias\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import gzip\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import  precision_score, balanced_accuracy_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93c51e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funciones\n",
    "def load_data():\n",
    "    # Define las columnas categóricas\n",
    "    global categorical_features\n",
    "    categorical_features = ['SEX', 'EDUCATION', 'MARRIAGE'] \n",
    "    global numeric_features \n",
    "    numeric_features = ['LIMIT_BAL', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6',\n",
    "        'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
    "        'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "    \n",
    "    train = pd.read_csv(\n",
    "        \"../files/input/train_data.csv.zip\",\n",
    "        index_col=False,\n",
    "        compression=\"zip\",\n",
    "    )\n",
    "    test = pd.read_csv(\n",
    "        \"../files/input/test_data.csv.zip\",\n",
    "        index_col=False,\n",
    "        compression=\"zip\",\n",
    "    )\n",
    "    return train, test\n",
    "\n",
    "def clear_data(df):\n",
    "    #Renombrar\n",
    "    df.rename(columns={\"default payment next month\": \"default\"}, inplace=True)\n",
    "    #Eliminacion de columna\n",
    "    df = df.drop(\"ID\", axis=1)\n",
    "    #Eliminacion elementos nulos \n",
    "    df.dropna(inplace=True)\n",
    "    #Cambia valores de educacion mayores a 4\n",
    "    df[\"EDUCATION\"] = df[\"EDUCATION\"].apply(lambda x: x if x<=4 else 4)\n",
    "    return df\n",
    "\n",
    "def make_train_test_split(df):\n",
    "    #Division en etiquetas \n",
    "    y_df =  df[\"default\"]\n",
    "    #Division en caracteristicas de entrada\n",
    "    x_df = df.drop(\"default\", axis=1)\n",
    "    return x_df, y_df\n",
    "\n",
    "\n",
    "def cross_validation(pipeline, param_grid, x_train, y_train):\n",
    "    #Evaluacion de hiperparametros\n",
    "    model = GridSearchCV(\n",
    "        estimator = pipeline,\n",
    "        param_grid = param_grid,\n",
    "        cv = 10,\n",
    "        scoring=\"balanced_accuracy\", #\"f1_score\"\n",
    "    )\n",
    "    #Aplicacion de GridSearchCV\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "def save_grid_search_model(model):\n",
    "    #Guardar mejor modelo\n",
    "    if not os.path.exists(\"../files/models\"):\n",
    "        os.makedirs(\"../files/models\")\n",
    "    with gzip.open(\"../files/models/model.pkl.gz\", \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "def eval_metrics(type_dataset, y_true, y_pred):\n",
    "    #         | Pronóstico\n",
    "    #         |  PP    PN\n",
    "    #---------|------------\n",
    "    #      P  |  TP    FN\n",
    "    # Real    |\n",
    "    #      N  |  FP    TN\n",
    "\n",
    "    #(1/2)*(TP/P + TN/N)\n",
    "    b_accuracy = balanced_accuracy_score(y_true=y_true, y_pred=y_pred,)\n",
    "    #TP/(TP + FP)\n",
    "    precision = precision_score(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred, \n",
    "        labels=None, \n",
    "        pos_label=1,\n",
    "        average=\"binary\",)\n",
    "    #TP/(TP + FN)\n",
    "    recall = recall_score(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred, \n",
    "        labels=None, \n",
    "        pos_label=1,\n",
    "        average=\"binary\",)\n",
    "    #2*(precision*recall)/(precision + recall)\n",
    "    f1 = f1_score(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        labels=None,\n",
    "        pos_label=1,\n",
    "        average=\"binary\",\n",
    "        sample_weight=None,\n",
    "        zero_division=\"warn\",)\n",
    "\n",
    "    #Formar diccionario de metricas \n",
    "    dic_metrics = { \"type\": \"metrics\",\n",
    "                   'dataset': type_dataset, \n",
    "                   'precision': precision , \n",
    "                   'balanced_accuracy': b_accuracy, \n",
    "                   'recall': recall, \n",
    "                   'f1_score': f1}\n",
    "    print(dic_metrics)\n",
    "    #Guardar metricas como archivo json\n",
    "    if not os.path.exists(\"../files/output\"):\n",
    "        os.makedirs(\"../files/output\")\n",
    "    with open(\"../files/output/metrics.json\", \"a\") as f:\n",
    "        json.dump(dic_metrics, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "def eval_confusion_matrix(type_dataset, y_true, y_pred):\n",
    "    #         | Pronóstico\n",
    "    #         |  PP    PN\n",
    "    #---------|------------\n",
    "    #      P  |  TP    FN\n",
    "    # Real    |\n",
    "    #      N  |  FP    TN\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true=y_true, y_pred=y_pred,).ravel()\n",
    "\n",
    "    #Formar diccionario de metricas \n",
    "    dic_confusion = {'type': 'cm_matrix', 'dataset': type_dataset, \n",
    "                   'true_0': {\"predicted_0\": int(tn), \"predicte_1\": int(fp)}, \n",
    "                   'true_1': {\"predicted_0\": int(fn), \"predicted_1\": int(tp)}}\n",
    "    print(dic_confusion)\n",
    "    #Guardar metricas como archivo json\n",
    "    if not os.path.exists(\"../files/output\"):\n",
    "        os.makedirs(\"../files/output\")\n",
    "    with open(\"../files/output/metrics.json\", \"a\") as f:\n",
    "        json.dump(dic_confusion, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "#---------------------------FUCTION SET------------------------------------------\n",
    "def dataset_manipulation():\n",
    "    #Carga de datos\n",
    "    train, test = load_data()\n",
    "    #Limpieza de datos\n",
    "    train = clear_data(train)\n",
    "    test = clear_data(test)\n",
    "    #Division en etiquetas y caracteristicas de entrada\n",
    "    x_train, y_train = make_train_test_split(train)\n",
    "    x_test, y_test = make_train_test_split(test)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def eval_model(model, x_train, y_train, x_test, y_test):\n",
    "    if os.path.exists(\"../files/output/metrics.json\"):\n",
    "        os.remove(\"../files/output/metrics.json\")\n",
    "    # Calculo de métricas\n",
    "    eval_metrics(\"train\", y_train, y_pred=model.best_estimator_.predict(x_train))\n",
    "    eval_metrics(\"test\", y_test, y_pred=model.best_estimator_.predict(x_test))\n",
    "    # Calculo matriz de confusión\n",
    "    eval_confusion_matrix(\"train\", y_train, y_pred=model.best_estimator_.predict(x_train))\n",
    "    eval_confusion_matrix(\"test\", y_test, y_pred=model.best_estimator_.predict(x_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d7b5967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------MODEL------------------------------------------\n",
    "def train_model(x_train, y_train):  \n",
    "    #----------------------PIPELINE------------------------------\n",
    "    # Crea el preprocesador\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            #Ej. df[Sex]-->\"1\",\"2\" por tanto la codificacion de esa columna sera un array de bit\n",
    "            # \"1\"-->[1,0] \"2\"-->[0,1]\n",
    "            ('one', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "            #Escala los valores numericos en un rango de 0 y 1\n",
    "            (\"minmax\", MinMaxScaler(feature_range=(0, 1)), numeric_features)\n",
    "        ],\n",
    "        remainder='passthrough'  # Deja las columnas numéricas igual\n",
    "    )\n",
    "    #Contruccion pipeline\n",
    "    pipeline = make_pipeline(\n",
    "    preprocessor,\n",
    "    SelectKBest(k=15),\n",
    "    LogisticRegression(),\n",
    "    )\n",
    "    #-------------------------PARAMETROS GRID-----------------------------\n",
    "    #Definicion de hiperparametros a evualuar \n",
    "    paramters_grid = {\n",
    "    'selectkbest__k': range(12, 18),  # Número de características a seleccionar\n",
    "    'logisticregression__solver': ['lbfgs', 'saga'],\n",
    "    'logisticregression__tol': [0.001],\n",
    "    'logisticregression__penalty': ['l1', 'l2'],\n",
    "    'logisticregression__C': [0.01, 1, 10],\n",
    "    'logisticregression__class_weight': [{0: 1, 1: 1.24}]\n",
    "    #'logisticregression__class_weight': [{0: 1, 1: 1.2},{0: 1, 1: 1.4},{0: 1, 1: 1.6},\n",
    "    #                                     {0: 1, 1: 1.8},{0: 1, 1: 2}],\n",
    "    }\n",
    "    #----------------------TRAIN CROSS-----------------------\n",
    "    model = cross_validation(pipeline=pipeline,\n",
    "                             param_grid=paramters_grid,\n",
    "                             x_train=x_train,\n",
    "                             y_train=y_train\n",
    "                             )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60954e0e",
   "metadata": {},
   "source": [
    "Ejecución del flujo principal para el dataset predefinido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a0b41c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga y manipulacion de datos \n",
    "x_train, y_train, x_test, y_test = dataset_manipulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74421774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "default\n",
       "0    16273\n",
       "1     4727\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Al verificar la cantidad de elementos de cada clase presentes en el dataset, \n",
    "#se determina que hay un desbalance entre las mismas, por tanto toca aplicar balanceo de la misma.\n",
    "#Clase 0: 16,273 (~77%)\n",
    "#Clase 1: 4,727 (~23%)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2d38484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "180 fits failed out of a total of 720.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1363, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 661, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1363, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1210, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 63, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.52225296 0.52257009 0.52225296 0.52225296 0.52232794 0.52232794\n",
      " 0.5232374  0.52313169 0.52392941 0.52440634 0.52680971 0.52851657\n",
      " 0.5232374  0.52314521 0.52323396 0.52415067 0.52720204 0.52741323\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.63603944 0.63660235 0.63673159 0.63882071 0.63826225 0.63807787\n",
      " 0.63276004 0.63312912 0.63445592 0.63594191 0.63502028 0.63424782\n",
      " 0.63369246 0.63425586 0.63440602 0.63550409 0.63467243 0.63433808\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.63683485 0.63775938 0.63764989 0.63959851 0.63964447 0.63980794\n",
      " 0.63480048 0.63452738 0.63556744 0.63789948 0.63758035 0.63750185\n",
      " 0.63629186 0.63734003 0.63725736 0.63872489 0.6389692  0.63908842]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6398079420098922\n",
      "{'logisticregression__C': 10, 'logisticregression__class_weight': {0: 1, 1: 1.24}, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'saga', 'logisticregression__tol': 0.001, 'selectkbest__k': 17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\Documentos\\Universidad-Materias\\Fundamentos_Analítica\\LAB-10-prediccion-del-default-usando-logreg-juloperag\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Definicion y entrenamiento de modelo\n",
    "model = train_model(x_train, y_train)  \n",
    "#Informacion del mejor modelo y ademas definirlo\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0b61ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvar mejor model\n",
    "save_grid_search_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bf90d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'metrics', 'dataset': 'train', 'precision': 0.6887778282598819, 'balanced_accuracy': 0.6393082718312573, 'recall': 0.32071081023905224, 'f1_score': 0.4376443418013857}\n",
      "{'type': 'metrics', 'dataset': 'test', 'precision': 0.7, 'balanced_accuracy': 0.654079064505956, 'recall': 0.34834992142482973, 'f1_score': 0.4651976215459951}\n",
      "{'type': 'cm_matrix', 'dataset': 'train', 'true_0': {'predicted_0': 15588, 'predicte_1': 685}, 'true_1': {'predicted_0': 3211, 'predicted_1': 1516}}\n",
      "{'type': 'cm_matrix', 'dataset': 'test', 'true_0': {'predicted_0': 6806, 'predicte_1': 285}, 'true_1': {'predicted_0': 1244, 'predicted_1': 665}}\n"
     ]
    }
   ],
   "source": [
    "#Evaluacion del Modelo con diversas metricas\n",
    "eval_model(model, x_train, y_train, x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
